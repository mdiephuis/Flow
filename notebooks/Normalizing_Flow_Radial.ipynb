{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing flow demos. \n",
    "References:\n",
    "* https://github.com/acids-ircam/pytorch_flows/blob/master/flows_01.ipynb\n",
    "* https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html\n",
    "* https://blog.evjang.com/2018/01/nf1.html\n",
    "* https://blog.evjang.com/2018/01/nf1.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torch.distributions.transforms as T\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid points\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
    "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadialFlow(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(RadialFlow, self).__init__()\n",
    "        self.z0 = nn.Parameter(torch.Tensor(1, dim))\n",
    "        self.beta = nn.Parameter(torch.Tensor(1))\n",
    "        self.alpha = nn.Parameter(torch.Tensor(1))    \n",
    "        self.dim = dim\n",
    "        self.init_parameters()\n",
    "        \n",
    "    def init_parameters(self):\n",
    "        for param in self.parameters():\n",
    "            param.data.uniform_(-0.01, 0.01)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        r = torch.norm(z - self.z0, dim=1).unsqueeze(1)\n",
    "        h = 1. / (self.alpha + r)\n",
    "        return z + self.beta * h * (z - self.z0)\n",
    "        \n",
    "    def log_abs_det_jacobian(self, z):\n",
    "        r = torch.norm(z - self.z0, dim=1).unsqueeze(1)\n",
    "        h = 1. / (self.alpha + r)\n",
    "        dh = - 1. / ((self.alpha + r) ** 2)\n",
    "        base = 1 + self.beta * h\n",
    "        det_grad =  (base + self.beta * dh * r) * base ** (self.dim - 1)\n",
    "        return torch.log(torch.abs(det_grad) + 1e-9)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_density(q0_density, flow, z):\n",
    "    # Apply our transform on coordinates\n",
    "    f_z = flow(torch.Tensor(z)).detach()\n",
    "    # Obtain our density\n",
    "    q1_density = q0_density.squeeze() / np.exp(flow.log_abs_det_jacobian(torch.Tensor(z)).detach().squeeze())\n",
    "    return q1_density, f_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "q0 = D.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "q0_density = torch.exp(q0.log_prob(torch.Tensor(z)))\n",
    "\n",
    "flow = RadialFlow(2)\n",
    "\n",
    "flow.z0.data = torch.Tensor([[0.5, 0.5]])\n",
    "flow.alpha.data = torch.Tensor([1])\n",
    "flow.beta.data = torch.Tensor([8])\n",
    "q1_density, f_z = change_density(q0_density, flow, z)\n",
    "# Plot this\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.hexbin(z[:,0], z[:,1], C=q0_density.numpy().squeeze(), cmap='rainbow')\n",
    "ax1.set_title('$q_0 = \\mathcal{N}(\\mathbf{0},\\mathbb{I})$', fontsize=18);\n",
    "ax2.hexbin(f_z[:,0], f_z[:,1], C=q1_density.numpy().squeeze(), cmap='rainbow')\n",
    "ax2.set_title('$q_1=radial(q_0)$', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invertible generative flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametric ReLU flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PReLU\n",
    "\n",
    "class PReLU_Flow(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(PReLU_Flow, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.Tensor([1]))\n",
    "        self.init_parameters()\n",
    "        \n",
    "    def init_parameters(self):\n",
    "        for param in self.parameters():\n",
    "            param.data.uniform_(-0.01, 0.99)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return torch.where(z >= 0, z, torch.abs(self.alpha) * z)\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        return torch.where(z >= 0, z, torch.abs(1. / self.alpha) * z)\n",
    "    \n",
    "    def log_abs_det_jacobian(self, z):\n",
    "        I = torch.ones_like(z)\n",
    "        J = torch.where(z >= 0, I, self.alpha * I)\n",
    "        log_det = torch.log(torch.abs(J) + 1e-5)\n",
    "        return torch.sum(log_det, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our base density\n",
    "q0 = D.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "q0_density = torch.exp(q0.log_prob(torch.Tensor(z)))\n",
    "# Our radial transform\n",
    "flow = RadialFlow(2) \n",
    "# Manually set the transform parameters (I know it is dirty ^^)\n",
    "flow.z0.data = torch.Tensor([[-0.5, -0.5]])\n",
    "flow.alpha.data = torch.Tensor([1])\n",
    "flow.beta.data = torch.Tensor([8])\n",
    "q1_density, f_z = change_density(q0_density, flow, z)\n",
    "# Our ReLU flow\n",
    "flow = PReLU_Flow(2) \n",
    "# Manually set the transform parameters (dirty again ^^)\n",
    "flow.alpha.data = torch.Tensor([0.5])\n",
    "q2_density, f_z2 = change_density(q1_density, flow, f_z)\n",
    "print(q2_density)\n",
    "print(f_z2)\n",
    "# Plot this\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax1.hexbin(z[:,0], z[:,1], C=q0_density.numpy().squeeze(), cmap='rainbow')\n",
    "ax1.set_title('$q_0 = \\mathcal{N}(\\mathbf{0},\\mathbb{I})$', fontsize=18);\n",
    "ax2.hexbin(f_z[:,0], f_z[:,1], C=q1_density.numpy().squeeze(), cmap='rainbow')\n",
    "ax2.set_title('$q_1=radial(q_0)$', fontsize=18);\n",
    "ax3.hexbin(f_z2[:,0], f_z2[:,1], C=q2_density.numpy().squeeze(), cmap='rainbow')\n",
    "ax3.set_title('$q_2=PReLU(q_1)$', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch normalizing flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormFlow(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, momentum=0.95, eps=1e-5):\n",
    "        super(BatchNormFlow, self).__init__()\n",
    "        # Running batch statistics\n",
    "        self.r_mean = torch.zeros(dim)\n",
    "        self.r_var = torch.ones(dim)\n",
    "        # Momentum\n",
    "        self.momentum = momentum\n",
    "        self.eps = eps\n",
    "        # Trainable scale and shift (cf. original paper)\n",
    "        self.gamma = nn.Parameter(torch.ones(dim))\n",
    "        self.beta = nn.Parameter(torch.zeros(dim))\n",
    "        \n",
    "    def forward(self, z):\n",
    "        if self.training:\n",
    "            # Current batch stats\n",
    "            self.b_mean = z.mean(0)\n",
    "            self.b_var = (z - self.b_mean).pow(2).mean(0) + self.eps\n",
    "            # Running mean and var\n",
    "            self.r_mean = self.momentum * self.r_mean + ((1 - self.momentum) * self.b_mean)\n",
    "            self.r_var = self.momentum * self.r_var + ((1 - self.momentum) * self.b_var)\n",
    "            mean = self.b_mean\n",
    "            var = self.b_var\n",
    "        else:\n",
    "            mean = self.r_mean\n",
    "            var = self.r_var\n",
    "        x_hat = (z - mean) / var.sqrt()\n",
    "        y = self.gamma * x_hat + self.beta\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, x):\n",
    "        if self.training:\n",
    "            mean = self.b_mean\n",
    "            var = self.b_var\n",
    "        else:\n",
    "            mean = self.r_mean\n",
    "            var = self.r_var\n",
    "        x_hat = (z - self.beta) / self.gamma\n",
    "        y = x_hat * var.sqrt() + mean\n",
    "        return y\n",
    "        \n",
    "    def log_abs_det_jacobian(self, z):\n",
    "        # Here we only need the variance\n",
    "        mean = z.mean(0)\n",
    "        var = (z - mean).pow(2).mean(0) + self.eps\n",
    "        log_det = torch.log(self.gamma) - 0.5 * torch.log(var + self.eps)\n",
    "        return torch.sum(log_det, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineLUFlow(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(AffineLUFlow, self).__init__()\n",
    "        weights = torch.Tensor(dim, dim)\n",
    "        nn.init.orthogonal_(weights)\n",
    "        P, L, U = linalg.lu(weights.numpy())\n",
    "        \n",
    "        self.P = torch.Tensor(P)\n",
    "        self.L = nn.Parameter(torch.Tensor(L))\n",
    "        self.U = nn.Parameter(torch.Tensor(U))\n",
    "        \n",
    "        # masks to enforce triangular matrices\n",
    "        self.mask_low = torch.tril(torch.ones_like(weights), -1)\n",
    "        self.mask_up = torch.triu(torch.ones_like(weights), -1)\n",
    "        self.I = torch.eye(weights.size(0))\n",
    "        \n",
    "        # compute s\n",
    "        self.s = nn.Parameter(torch.Tensor(np.diag(U)))\n",
    "        \n",
    "    def forward(self, z):\n",
    "        L = self.L * self.mask_low + self.I\n",
    "        U = self.U * self.mask_up + torch.diag(self.s)\n",
    "        weights = self.P @ L @ U\n",
    "        return z @ weights\n",
    "    \n",
    "    def inverse(self, z):\n",
    "        L = self.L * self.mask_low + self.I\n",
    "        U = self.U * self.mask_up + torch.diag(self.s)\n",
    "        weights = self.P @ L @ U\n",
    "        return z @ torch.inverse(self.weights)\n",
    "    \n",
    "    def log_abs_det_jacobian(self, z):\n",
    "        return torch.sum(torch.log(torch.abs(self.s))).unsqueeze(0).repeat(z.size(0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
